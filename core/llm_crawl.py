import requests
import json
import pandas as pd
from datetime import datetime
import time

# ===================== é…ç½®é¡¹ =====================


INDUSTRY_NAME = "æ–°èƒ½æºè¡Œä¸š"
KEYWORDS = ["è¡¥è´´æ”¿ç­–", "æŠ€æœ¯çªç ´", "ä¼ä¸šè¥æ”¶", "ä»·æ ¼æ³¢åŠ¨", "è¡Œä¸šé£é™©"]
START_DATE = "2025-12-01"
END_DATE = "2025-12-08"
NEWS_PER_KEYWORD = 5  # æ¯ä¸ªå…³é”®è¯é‡‡é›†çš„æ–°é—»æ•°é‡

# APIé…ç½®
DEEPSEEK_API_URL = "https://api.deepseek.com/v1/chat/completions"
NEWS_API_URL = "https://newsapi.org/v2/everything"

HEADERS = {
    "Authorization": f"Bearer {DEEPSEEK_API_KEY}",
    "Content-Type": "application/json"
}


def search_real_news(keyword, max_results=10):
    """
    ä½¿ç”¨NewsAPIæœç´¢çœŸå®æ–°é—»
    è¿”å›ï¼šæ–°é—»åˆ—è¡¨
    """
    if not NEWS_API_KEY or NEWS_API_KEY == "YOUR_NEWS_API_KEY":
        print(f"âš ï¸  æœªé…ç½®NewsAPIå¯†é’¥ï¼Œè·³è¿‡çœŸå®æ–°é—»æœç´¢")
        return []

    params = {
        "q": f"{keyword} {INDUSTRY_NAME}",
        "apiKey": NEWS_API_KEY,
        "from": START_DATE,
        "to": END_DATE,
        "language": "zh",
        "sortBy": "publishedAt",
        "pageSize": max_results
    }

    try:
        print(f"ğŸ” æ­£åœ¨æœç´¢ã€Œ{keyword}ã€ç›¸å…³æ–°é—»...")
        response = requests.get(NEWS_API_URL, params=params, timeout=30)
        response.raise_for_status()
        data = response.json()

        if data.get("status") == "ok" and data.get("articles"):
            articles = data["articles"]
            print(f"âœ… æ‰¾åˆ°ã€Œ{keyword}ã€ç›¸å…³æ–°é—» {len(articles)} æ¡")
            return articles
        else:
            print(f"âš ï¸  æœªæ‰¾åˆ°ã€Œ{keyword}ã€ç›¸å…³æ–°é—»")
            return []
    except Exception as e:
        print(f"âŒ NewsAPIæœç´¢å¤±è´¥: {e}")
        return []


def generate_structured_news_data():
    """
    ç”Ÿæˆç»“æ„åŒ–æ–°é—»æ•°æ®
    ä½¿ç”¨DeepSeekæ ¹æ®å…³é”®è¯ç”Ÿæˆæ¨¡æ‹Ÿæ–°é—»æ•°æ®
    """
    all_news = []

    for keyword in KEYWORDS:
        print(f"\nğŸ“ ç”Ÿæˆã€Œ{keyword}ã€ç›¸å…³æ–°é—»æ•°æ®...")

        # æ„å»ºPromptï¼Œè¦æ±‚ç”Ÿæˆç»“æ„åŒ–æ•°æ®
        prompt = f"""
        è¯·ä¸º{INDUSTRY_NAME}åœ¨{START_DATE}è‡³{END_DATE}æœŸé—´ç”Ÿæˆ{NEWS_PER_KEYWORD}æ¡ä¸ã€Œ{keyword}ã€ç›¸å…³çš„æ¨¡æ‹Ÿæ–°é—»æ•°æ®ã€‚

        è¦æ±‚ï¼š
        1. æ¯æ¡æ–°é—»å¿…é¡»æ˜¯æ¨¡æ‹Ÿçš„çœŸå®æ–°é—»ï¼Œå†…å®¹è¯¦å®å¯ä¿¡
        2. æ•°æ®æ ¼å¼ä¸ºJSONæ•°ç»„ï¼ŒåŒ…å«ä»¥ä¸‹å­—æ®µï¼š
           - æ ‡é¢˜ (title): æ–°é—»æ ‡é¢˜
           - å‘å¸ƒæ—¶é—´ (publish_time): æ ¼å¼ä¸ºYYYY-MM-DD HH:MM:SS
           - æ¥æº (source): æ–°é—»åª’ä½“åç§°ï¼ˆå¦‚ï¼šè´¢ç»ç½‘ã€æ–°åç½‘ã€æ–°æµªè´¢ç»ç­‰ï¼‰
           - æ ¸å¿ƒæ‘˜è¦ (summary): æ–°é—»æ ¸å¿ƒå†…å®¹æ‘˜è¦ï¼ˆ150-300å­—ï¼‰
           - è¯¦æƒ…é“¾æ¥ (url): æ¨¡æ‹Ÿçš„æ–°é—»é“¾æ¥ï¼ˆå¯ä»¥ä¸ºç©ºå­—ç¬¦ä¸²ï¼‰
        3. æ–°é—»å†…å®¹åº”åŸºäº{INDUSTRY_NAME}çš„å®é™…æƒ…å†µï¼Œåæ˜ å¸‚åœºåŠ¨æ€
        4. åªè¿”å›JSONæ•°ç»„ï¼Œä¸è¦æ·»åŠ ä»»ä½•è§£é‡Šæ–‡å­—

        ç¤ºä¾‹æ ¼å¼ï¼š
        [
          {{
            "title": "æ–°èƒ½æºæ±½è½¦è¡¥è´´æ”¿ç­–å†æ¬¡å»¶é•¿ä¸‰å¹´",
            "publish_time": "2025-12-05 10:30:00",
            "source": "è´¢ç»ç½‘",
            "summary": "è´¢æ”¿éƒ¨ä»Šæ—¥å‘å¸ƒé€šçŸ¥ï¼Œæ–°èƒ½æºæ±½è½¦è´­ç½®è¡¥è´´æ”¿ç­–å°†å»¶é•¿è‡³2028å¹´åº•...",
            "url": "https://example.com/news/12345"
          }}
        ]
        """

        payload = {
            "model": "deepseek-chat",
            "messages": [
                {"role": "user", "content": prompt}
            ],
            "temperature": 0.7,
            "max_tokens": 2000
        }

        try:
            response = requests.post(
                DEEPSEEK_API_URL,
                headers=HEADERS,
                json=payload,
                timeout=30
            )
            response.raise_for_status()
            result = response.json()

            # æå–JSONæ•°æ®
            content = result["choices"][0]["message"]["content"].strip()

            # æ¸…ç†å¯èƒ½çš„Markdownä»£ç å—æ ‡è®°
            if "```json" in content:
                content = content.split("```json")[1].split("```")[0].strip()
            elif "```" in content:
                content = content.split("```")[1].split("```")[0].strip()

            # è§£æJSON
            news_data = json.loads(content)

            # æ·»åŠ è¡Œä¸šå’Œå…³é”®è¯ä¿¡æ¯
            for news_item in news_data:
                news_item["æ‰€å±è¡Œä¸š"] = INDUSTRY_NAME
                news_item["é‡‡é›†å…³é”®è¯"] = keyword
                news_item["é‡‡é›†æ—¶é—´"] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")

                # ç¡®ä¿æ‰€æœ‰å¿…éœ€å­—æ®µéƒ½å­˜åœ¨
                if "url" not in news_item:
                    news_item["url"] = ""

                all_news.append(news_item)

            print(f"âœ… æˆåŠŸç”Ÿæˆã€Œ{keyword}ã€æ–°é—» {len(news_data)} æ¡")

            # é¿å…APIè°ƒç”¨è¿‡äºé¢‘ç¹
            time.sleep(1)

        except json.JSONDecodeError as e:
            print(f"âŒ JSONè§£æå¤±è´¥: {e}")
            print("åŸå§‹å†…å®¹:", content[:500])
        except Exception as e:
            print(f"âŒ ç”Ÿæˆã€Œ{keyword}ã€æ–°é—»å¤±è´¥: {e}")
            continue

    return all_news


def get_hybrid_news_data():
    """
    æ··åˆæ¨¡å¼ï¼šå…ˆå°è¯•è·å–çœŸå®æ–°é—»ï¼Œä¸è¶³éƒ¨åˆ†ç”¨æ¨¡æ‹Ÿæ•°æ®è¡¥å……
    """
    all_news = []

    for keyword in KEYWORDS:
        print(f"\n{'=' * 60}")
        print(f"å¤„ç†å…³é”®è¯: {keyword}")

        # å…ˆå°è¯•è·å–çœŸå®æ–°é—»
        real_articles = search_real_news(keyword, max_results=NEWS_PER_KEYWORD)

        collected_count = 0

        # å¤„ç†çœŸå®æ–°é—»
        if real_articles:
            for article in real_articles[:NEWS_PER_KEYWORD]:
                news_item = {
                    "title": article.get("title", "æ— æ ‡é¢˜"),
                    "publish_time": article.get("publishedAt", "").replace("T", " ").replace("Z", ""),
                    "source": article.get("source", {}).get("name", "æœªçŸ¥æ¥æº"),
                    "summary": article.get("description", article.get("content", "æ— æ‘˜è¦"))[:300],
                    "url": article.get("url", ""),
                    "æ‰€å±è¡Œä¸š": INDUSTRY_NAME,
                    "é‡‡é›†å…³é”®è¯": keyword,
                    "é‡‡é›†æ—¶é—´": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                    "æ•°æ®æ¥æº": "NewsAPI"
                }
                all_news.append(news_item)
                collected_count += 1

        # å¦‚æœçœŸå®æ–°é—»ä¸è¶³ï¼Œç”¨æ¨¡æ‹Ÿæ•°æ®è¡¥å……
        if collected_count < NEWS_PER_KEYWORD:
            needed_count = NEWS_PER_KEYWORD - collected_count
            print(f"éœ€è¦è¡¥å…… {needed_count} æ¡æ¨¡æ‹Ÿæ–°é—»")

            # ç”Ÿæˆæ¨¡æ‹Ÿæ–°é—»
            prompt = f"""
            è¯·ä¸º{INDUSTRY_NAME}ç”Ÿæˆ{needed_count}æ¡ä¸ã€Œ{keyword}ã€ç›¸å…³çš„æ¨¡æ‹Ÿæ–°é—»æ•°æ®ã€‚

            è¦æ±‚ï¼š
            1. æ¯æ¡æ–°é—»å¿…é¡»æ˜¯æ¨¡æ‹Ÿçš„çœŸå®æ–°é—»ï¼Œå†…å®¹è¯¦å®å¯ä¿¡
            2. æ•°æ®æ ¼å¼ä¸ºJSONæ•°ç»„ï¼ŒåŒ…å«ä»¥ä¸‹å­—æ®µï¼š
               - title: æ–°é—»æ ‡é¢˜
               - publish_time: æ ¼å¼ä¸ºYYYY-MM-DD HH:MM:SSï¼ˆåœ¨{START_DATE}è‡³{END_DATE}æœŸé—´ï¼‰
               - source: æ–°é—»åª’ä½“åç§°
               - summary: æ–°é—»æ ¸å¿ƒå†…å®¹æ‘˜è¦ï¼ˆ150-300å­—ï¼‰
               - url: æ¨¡æ‹Ÿçš„æ–°é—»é“¾æ¥ï¼ˆå¯ä»¥ä¸ºç©ºå­—ç¬¦ä¸²ï¼‰
            3. åªè¿”å›JSONæ•°ç»„ï¼Œä¸è¦æ·»åŠ ä»»ä½•è§£é‡Šæ–‡å­—
            """

            payload = {
                "model": "deepseek-chat",
                "messages": [
                    {"role": "user", "content": prompt}
                ],
                "temperature": 0.7,
                "max_tokens": 1500
            }

            try:
                response = requests.post(DEEPSEEK_API_URL, headers=HEADERS, json=payload, timeout=30)
                response.raise_for_status()
                result = response.json()

                content = result["choices"][0]["message"]["content"].strip()

                # æ¸…ç†å¯èƒ½çš„Markdownä»£ç å—æ ‡è®°
                if "```json" in content:
                    content = content.split("```json")[1].split("```")[0].strip()
                elif "```" in content:
                    content = content.split("```")[1].split("```")[0].strip()

                # è§£æJSON
                simulated_news = json.loads(content)

                # æ·»åŠ é¢å¤–ä¿¡æ¯
                for news_item in simulated_news[:needed_count]:
                    news_item["æ‰€å±è¡Œä¸š"] = INDUSTRY_NAME
                    news_item["é‡‡é›†å…³é”®è¯"] = keyword
                    news_item["é‡‡é›†æ—¶é—´"] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                    news_item["æ•°æ®æ¥æº"] = "DeepSeekæ¨¡æ‹Ÿ"

                    if "url" not in news_item:
                        news_item["url"] = ""

                    all_news.append(news_item)

                print(f"âœ… è¡¥å……æ¨¡æ‹Ÿæ–°é—» {min(needed_count, len(simulated_news))} æ¡")

            except Exception as e:
                print(f"âŒ è¡¥å……æ¨¡æ‹Ÿæ–°é—»å¤±è´¥: {e}")

        print(
            f"ğŸ“Š å…³é”®è¯ã€Œ{keyword}ã€æ€»è®¡é‡‡é›† {min(NEWS_PER_KEYWORD, len(real_articles) + (NEWS_PER_KEYWORD - collected_count))} æ¡æ–°é—»")

    return all_news


def save_to_excel(news_data, filename=None):
    """å°†æ–°é—»æ•°æ®ä¿å­˜ä¸ºExcelæ–‡ä»¶"""
    if not news_data:
        print("âš ï¸  æ²¡æœ‰æ•°æ®å¯ä¿å­˜")
        return None

    df = pd.DataFrame(news_data)

    # é‡å‘½ååˆ—ï¼Œä½¿å…¶æ›´æ˜“è¯»
    column_mapping = {
        "title": "æ ‡é¢˜",
        "publish_time": "å‘å¸ƒæ—¶é—´",
        "source": "æ¥æº",
        "summary": "æ ¸å¿ƒæ‘˜è¦",
        "url": "è¯¦æƒ…é“¾æ¥"
    }

    df.rename(columns=column_mapping, inplace=True)

    # é‡æ–°æ’åˆ—åˆ—é¡ºåº
    preferred_order = ["æ ‡é¢˜", "å‘å¸ƒæ—¶é—´", "æ¥æº", "æ ¸å¿ƒæ‘˜è¦", "æ‰€å±è¡Œä¸š",
                       "é‡‡é›†å…³é”®è¯", "é‡‡é›†æ—¶é—´", "æ•°æ®æ¥æº", "è¯¦æƒ…é“¾æ¥"]

    # åªä¿ç•™å­˜åœ¨çš„åˆ—
    ordered_columns = [col for col in preferred_order if col in df.columns]
    df = df[ordered_columns]

    # ç”Ÿæˆæ–‡ä»¶å
    if filename is None:
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        filename = f"{INDUSTRY_NAME}_æ–°é—»æ•°æ®_{timestamp}.xlsx"

    # ä¿å­˜åˆ°Excel
    df.to_excel(filename, index=False)
    print(f"ğŸ’¾ æ•°æ®å·²ä¿å­˜åˆ°: {filename}")

    return df, filename


def main():
    """ä¸»å‡½æ•°"""
    print(f"ğŸš€ å¼€å§‹é‡‡é›†ã€Œ{INDUSTRY_NAME}ã€æ–°é—»æ•°æ®")
    print(f"ğŸ“… æ—¶é—´èŒƒå›´: {START_DATE} è‡³ {END_DATE}")
    print(f"ğŸ”‘ å…³é”®è¯: {', '.join(KEYWORDS)}")
    print(f"ğŸ“Š æ¯ä¸ªå…³é”®è¯é‡‡é›†æ•°é‡: {NEWS_PER_KEYWORD}æ¡")
    print("=" * 60)

    # é€‰æ‹©æ•°æ®é‡‡é›†æ¨¡å¼
    print("\nè¯·é€‰æ‹©æ•°æ®é‡‡é›†æ¨¡å¼:")
    print("1. çº¯æ¨¡æ‹Ÿæ•°æ® (ä½¿ç”¨DeepSeekç”Ÿæˆ)")
    print("2. æ··åˆæ¨¡å¼ (å…ˆå°è¯•çœŸå®æ–°é—»ï¼Œä¸è¶³éƒ¨åˆ†ç”¨æ¨¡æ‹Ÿæ•°æ®è¡¥å……)")
    print("3. ä»…çœŸå®æ–°é—» (éœ€è¦é…ç½®NewsAPIå¯†é’¥)")

    choice = input("è¯·è¾“å…¥é€‰æ‹© (1/2/3, é»˜è®¤1): ").strip()

    if choice == "3" and (not NEWS_API_KEY or NEWS_API_KEY == "YOUR_NEWS_API_KEY"):
        print("âŒ é€‰æ‹©äº†ä»…çœŸå®æ–°é—»æ¨¡å¼ä½†æœªé…ç½®NewsAPIå¯†é’¥ï¼Œå°†ä½¿ç”¨æ··åˆæ¨¡å¼")
        choice = "2"

    news_data = []

    if choice == "2":
        print("\nğŸ“¡ ä½¿ç”¨æ··åˆæ¨¡å¼é‡‡é›†æ•°æ®...")
        news_data = get_hybrid_news_data()
    elif choice == "3":
        print("\nğŸ“¡ ä½¿ç”¨ä»…çœŸå®æ–°é—»æ¨¡å¼...")
        # è¿™é‡Œå¯ä»¥å•ç‹¬å®ç°ä»…çœŸå®æ–°é—»çš„é€»è¾‘
        # ä¸ºäº†ç®€åŒ–ï¼Œæˆ‘ä»¬å…ˆä½¿ç”¨æ··åˆæ¨¡å¼
        print("âš ï¸  æ­¤æ¨¡å¼éœ€è¦å®Œæ•´å®ç°ï¼Œæš‚æ—¶ä½¿ç”¨æ··åˆæ¨¡å¼")
        news_data = get_hybrid_news_data()
    else:
        print("\nğŸ¤– ä½¿ç”¨çº¯æ¨¡æ‹Ÿæ•°æ®æ¨¡å¼...")
        news_data = generate_structured_news_data()

    # ä¿å­˜æ•°æ®
    if news_data:
        df, filename = save_to_excel(news_data)

        # æ˜¾ç¤ºæ•°æ®ç»Ÿè®¡
        print(f"\nğŸ“ˆ æ•°æ®ç»Ÿè®¡:")
        print(f"æ€»æ–°é—»æ¡æ•°: {len(news_data)}")
        print(f"æ¶‰åŠå…³é”®è¯: {', '.join(set([n.get('é‡‡é›†å…³é”®è¯', '') for n in news_data]))}")

        # æ˜¾ç¤ºå‰å‡ æ¡æ•°æ®
        print(f"\nğŸ“° æ•°æ®é¢„è§ˆ (å‰5æ¡):")
        print(df.head().to_string(index=False))

        # æŒ‰å…³é”®è¯ç»Ÿè®¡
        if 'é‡‡é›†å…³é”®è¯' in df.columns:
            print(f"\nğŸ“Š æŒ‰å…³é”®è¯ç»Ÿè®¡:")
            keyword_counts = df['é‡‡é›†å…³é”®è¯'].value_counts()
            for keyword, count in keyword_counts.items():
                print(f"  {keyword}: {count}æ¡")
    else:
        print("âŒ æœªé‡‡é›†åˆ°ä»»ä½•æ•°æ®")


if __name__ == "__main__":
    main()